# -*- coding: utf-8 -*-
"""Gemini_Semantic_Search

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ApuDGPj-jYN6TqzejIPnzqK8bGsgebXN
"""

!pip install -U -q google-generativeai

#Importações e configurações iniciais
import numpy as np
import pandas as pd
import google.generativeai as genai

# Substitua 'YOUR_API_KEY' pela sua chave de API do Google

GOOGLE_API_KEY="AIzaSyBJyrhB0imnOL9FIjoA-bKJL9jX58BVB84"
genai.configure(api_key=GOOGLE_API_KEY)

# Lista os modelos disponíveis para embedding
for m in genai.list_models():
  if 'embedContent' in m.supported_generation_methods:
    print(m.name)

#Exemplo de embedding
title = "A próxima geração de IA para desenvolvedores e Google Workspace"
sample_text = ("Título: A próxima geração de IA para desenvolvedores e Google Workspace"
    "\n"
    "Artigo completo:\n"
    "\n"
    "Gemini API & Google AI Studio: Uma maneira acessível de explorar e criar protótipos com aplicações de IA generativa")

# Gera embeddings para o texto de exemplo

embeddings = genai.embed_content(model="models/embedding-001",
                                 content=sample_text,
                                 title=title,
                                 task_type="RETRIEVAL_DOCUMENT")

print(embeddings)

#Listagem de documentos que serão buscados
# Define três documentos de exemplo
DOCUMENT1 = {
    "Título": "Operação do sistema de controle climático",
    "Conteúdo": "O Googlecar tem um sistema de controle climático que permite ajustar a temperatura e o fluxo de ar no carro. Para operar o sistema de controle climático, use os botões e botões localizados no console central.  Temperatura: O botão de temperatura controla a temperatura dentro do carro. Gire o botão no sentido horário para aumentar a temperatura ou no sentido anti-horário para diminuir a temperatura. Fluxo de ar: O botão de fluxo de ar controla a quantidade de fluxo de ar dentro do carro. Gire o botão no sentido horário para aumentar o fluxo de ar ou no sentido anti-horário para diminuir o fluxo de ar. Velocidade do ventilador: O botão de velocidade do ventilador controla a velocidade do ventilador. Gire o botão no sentido horário para aumentar a velocidade do ventilador ou no sentido anti-horário para diminuir a velocidade do ventilador. Modo: O botão de modo permite que você selecione o modo desejado. Os modos disponíveis são: Auto: O carro ajustará automaticamente a temperatura e o fluxo de ar para manter um nível confortável. Cool (Frio): O carro soprará ar frio para dentro do carro. Heat: O carro soprará ar quente para dentro do carro. Defrost (Descongelamento): O carro soprará ar quente no para-brisa para descongelá-lo."}

DOCUMENT2 = {
    "Título": "Touchscreen",
    "Conteúdo": "O seu Googlecar tem uma grande tela sensível ao toque que fornece acesso a uma variedade de recursos, incluindo navegação, entretenimento e controle climático. Para usar a tela sensível ao toque, basta tocar no ícone desejado.  Por exemplo, você pode tocar no ícone \"Navigation\" (Navegação) para obter direções para o seu destino ou tocar no ícone \"Music\" (Música) para reproduzir suas músicas favoritas."}

DOCUMENT3 = {
    "Título": "Mudança de marchas",
    "Conteúdo": "Seu Googlecar tem uma transmissão automática. Para trocar as marchas, basta mover a alavanca de câmbio para a posição desejada.  Park (Estacionar): Essa posição é usada quando você está estacionado. As rodas são travadas e o carro não pode se mover. Marcha à ré: Essa posição é usada para dar ré. Neutro: Essa posição é usada quando você está parado em um semáforo ou no trânsito. O carro não está em marcha e não se moverá a menos que você pressione o pedal do acelerador. Drive (Dirigir): Essa posição é usada para dirigir para frente. Low: essa posição é usada para dirigir na neve ou em outras condições escorregadias."}

documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]

# Cria um DataFrame com os documentos
df = pd.DataFrame(documents)
df.columns = ["Titulo", "Conteudo"]
df

# Define o modelo de embedding a ser usado
model = "models/embedding-001"

# Define uma função para gerar embeddings para um título e texto
def embed_fn(title, text):
  return genai.embed_content(model=model,
                                 content=text,
                                 title=title,
                                 task_type="RETRIEVAL_DOCUMENT")["embedding"]

# Gera embeddings para cada documento no DataFrame
df["Embeddings"] = df.apply(lambda row: embed_fn(row["Titulo"], row["Conteudo"]), axis=1)
df

# Define uma função para gerar embeddings para uma consulta e buscar o documento mais relevante
# Gera embedding para a consulta
def gerar_e_buscar_consulta(consulta, base, model):
  embedding_da_consulta = genai.embed_content(model=model,
                                 content=consulta,
                                 task_type="RETRIEVAL_QUERY")["embedding"]

# Calcula o produto escalar entre os embeddings da consulta e dos documentos

  produtos_escalares = np.dot(np.stack(df["Embeddings"]), embedding_da_consulta)

# Encontra o índice do documento com o maior produto escalar

  indice = np.argmax(produtos_escalares)

# Retorna o conteúdo do documento mais relevante
  return df.iloc[indice]["Conteudo"]

# Define uma consulta de exemplo
consulta = "Como faço para trocar marchas em um carro do Google?"

# Busca o documento mais relevante para a consulta

trecho = gerar_e_buscar_consulta(consulta, df, model)
print(trecho)

# Define configurações para geração de texto
generation_config = {
  "temperature": 0, # Define a criatividade como 0, para gerar texto mais determinístico
  "candidate_count": 1 # Define o número de candidatos como 1, para gerar apenas uma resposta
}

# Define um prompt para reescrever o trecho de forma mais descontraída
prompt = f"Reescreva esse texto de uma forma mais descontraída, sem adicionar informações que não façam parte do texto: {trecho}"

# Usa o modelo Gemini Pro para gerar a resposta

model_2 = genai.GenerativeModel("gemini-1.0-pro",
                                generation_config=generation_config)
response = model_2.generate_content(prompt)
print(response.text)